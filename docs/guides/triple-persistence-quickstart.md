# üöÄ Triple-Persistence Quickstart Guide (Para Dummies)

**Fecha**: 2026-01-10
**Versi√≥n**: 1.0.0
**Audiencia**: Desarrolladores, investigadores sin experiencia en Neo4j/LLMs

---

## üìö ¬øQu√© vas a aprender?

Este manual te ense√±a a usar **2 sistemas en paralelo**:

1. **GenAI Stack** (Laboratorio) - Para experimentar y aprender
2. **LlamaIndex MVP** (Producci√≥n) - Para tu investigaci√≥n real

**Tiempo estimado**: 2-3 horas para setup completo

---

## üéØ FASE 1: GenAI Stack (Laboratorio)

### ¬øQu√© es GenAI Stack?

Piensa en GenAI Stack como **un laboratorio pre-armado**:
- Neo4j (base de datos graph+vector)
- Ollama (LLMs locales)
- LangChain (framework RAG)
- 5 aplicaciones de ejemplo

**Objetivo**: Ver funcionando Neo4j + Ollama + Vector Search en **5 minutos**

---

### Paso 1.1: Prerrequisitos

Verifica que tienes instalado:

```powershell
# Docker Desktop
docker --version
# Debe mostrar: Docker version 24.x o superior

# Ollama (OPCIONAL - puedes usar contenedor Docker tambi√©n)
ollama list
# Si est√° instalado, muestra modelos

# Git
git --version
```

**Si falta Docker Desktop**:
- Descargar: https://www.docker.com/products/docker-desktop/

**Ollama - TIENES 2 OPCIONES**:

**OPCI√ìN A: TODO EN DOCKER (RECOMENDADO PARA EMPEZAR)**
- No necesitas instalar Ollama localmente
- Usa: `docker compose --profile linux up`
- Funciona en Windows/Mac gracias a Docker Desktop (WSL2/VM)

**OPCI√ìN B: OLLAMA NATIVO (MEJOR RENDIMIENTO GPU)**
- Descargar: https://ollama.ai/download
- Mejor rendimiento con GPU local
- Usa: `docker compose up` (sin --profile)

---

### Paso 1.2: Instalar GenAI Stack

```powershell
# Ya est√° clonado en:
cd C:\proyectos\aleia-melquisedec\_lab\genai-stack

# Verificar archivos
lsIniciar GenAI Stack

**OPCI√ìN A: TODO EN DOCKER (SIN OLLAMA LOCAL)**

```powershell
cd C:\proyectos\aleia-melquisedec\_lab\genai-stack

# Editar .env para usar Ollama en Docker
# Cambiar: OLLAMA_BASE_URL=http://llm:11434

# Iniciar con perfil Linux (incluye Ollama)
docker compose --profile linux up -d

# Esperar a que todo est√© listo (2 minutos)
Start-Sleep -Seconds 120

# Verificar contenedores
docker ps
# Debes ver: database, llm, pull-model, bot, loader
```

**OPCI√ìN B: OLLAMA NATIVO (SI YA LO INSTALASTE)**

```powershell
# Terminal 1: Iniciar Ollama
ollama serve

# Terminal 2: Descargar modelos
ollama pull qwen2.5:latest
ollama pull nomic-embed-text

# Terminal 3: Iniciar stack
cd C:\proyectos\aleia-melquisedec\_lab\genai-stack
docker compose up -d

# Verificar
docker ps
```

**Tiempo**:
- Primera vez: 2-3 minutos (descarga im√°genes)
- Subsecuentes: 30 segundosC:\proyectos\aleia-melquisedec\_lab\genai-stack

# Iniciar servicios (Neo4j + apps)
docker-compose up -d database

# Esperar a que Neo4j est√© listo (30 segundos)
Start-Sleep -Seconds 30

# Verificar que Neo4j est√° corriendo
docker ps
# Debes ver: genai-stack-database-1 (healthy)
```

**Puertos abiertos**:
- `7474`: Neo4j Browser (interfaz web)
- `7687`: Neo4j Bolt (conexi√≥n program√°tica)

---

### Paso 1.4: Abrir Neo4j Browser

```powershell
# Abrir en navegador
start http://localhost:7474

# Credenciales (ya configuradas en .env)
# Usuario: neo4j
# Contrase√±a: password
```

**Prueba tu primera query Cypher**:

```cypher
// Ver qu√© nodos existen (debe estar vac√≠o)
MATCH (n) RETURN n LIMIT 25;

// Crear nodo de prueba
CREATE (d:Document {title: "Mi primer documento", text: "Hola Neo4j!"});

// Ver el nodo creado
MATCH (d:Document) RETURN d;
```

**üéâ Si ves el nodo, Neo4j funciona correctamente!**

---

### Paso 1.5: Iniciar Apps de Ejemplo

```powershell
cd C:\proyectos\aleia-melquisedec\_lab\genai-stack

# Iniciar chatbot de soporte
docker-compose up -d bot

# Esperar 30 segundos
Start-Sleep -Seconds 30

# Abrir chatbot
start http://localhost:8501
```

**Apps disponibles**:
- `8501`: Support Bot (chatbot con RAG)
- `8502`: Loader (carga datos StackOverflow)
- `8503`: PDF Bot (Q&A sobre PDFs)
- `8504`: API (REST API)
- `8505`: Frontend (UI Svelte)

---

### Paso 1.6: Experimentar con Datos

**Opci√≥n A: Cargar datos StackOverflow**

```powershell
# Iniciar loader
docker-compose up -d loader

# Ver logs (ver√°s preguntas siendo ingestadas)
docker logs genai-stack-loader-1 -f
```

**Opci√≥n B: Subir tus propios PDFs**

```powershell
# Iniciar PDF bot
docker-compose up -d pdf_bot

# Abrir interfaz
start http://localhost:8503

# Subir PDF y hacer preguntas!
```

---

### Paso 1.7: Inspeccionar el Grafo

Vuelve a Neo4j Browser (`http://localhost:7474`) y ejecuta:

```cypher
// Contar nodos creados
MATCH (q:Question) RETURN count(q) AS total_questions;
MATCH (a:Answer) RETURN count(a) AS total_answers;

// Ver estructura del grafo
CALL db.schema.visualization();

// Ver embeddings (vectores)
MATCH (q:Question)
WHERE q.embedding IS NOT NULL
RETURN q.title, size(q.embedding) AS embedding_dimension
LIMIT 5;
```

**Debes ver**:
- Nodos `Question` y `Answer`
- Relaciones `[:ANSWERS]`, `[:TAGGED]`
- Embeddings como arrays de n√∫meros

---

### Paso 1.9: Probar Vector Search

```cypher
// Buscar preguntas similares (vector search)
// NOTA: Esto requiere datos cargados primero

MATCH (q:Question)
CALL db.index.vector.queryNodes('stackoverflow', 5, q.embedding)
YIELD node, score
RETURN node.title AS similar_question, score
LIMIT 5;
```

**üéØ Objetivo cumplido**: Has visto Neo4j Vector Search funcionando!

---

### Paso 1.10: Detener GenAI Stack

Cuando termines de experimentar:

```powershell
cd C:\proyectos\aleia-melquisedec\_lab\genai-stack

# Detener servicios (mantiene datos)
docker-compose down

# Si quieres borrar datos y empezar de cero
docker-compose down -v
```

---

## üèóÔ∏è FASE 2: LlamaIndex MVP (Producci√≥n)

### ¬øQu√© es LlamaIndex MVP?

Es **tu sistema personalizado** para research-autopoietic-template:
- Triple-Persistence (MD + Graph + Vector)
- C√≥digo limpio (Hexagonal Architecture)
- Tests automatizados
- Dise√±ado para documentos de investigaci√≥n

**Objetivo**: Sistema production-ready en 1 semana

---

### Arquitectura LlamaIndex MVP

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    research-autopoietic-template            ‚îÇ
‚îÇ  (010-define/, 020-conceive/, 030-design/, 040-build/)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              TriplePersistencePipeline                      ‚îÇ
‚îÇ  1. Leer Markdown ‚Üí 2. Chunking ‚Üí 3. Embeddings            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Neo4j 5.26                             ‚îÇ
‚îÇ  ‚Ä¢ Graph: (:Document)-[:HAS_CHUNK]->(:Chunk)               ‚îÇ
‚îÇ  ‚Ä¢ Vector: HNSW index on Chunk.embedding (768 dim)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   HybridRetriever                           ‚îÇ
‚îÇ  ‚Ä¢ Vector Search (top-k similar chunks)                     ‚îÇ
‚îÇ  ‚Ä¢ Graph Traversal (enriquecer con metadata)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### Paso 2.1: Estructura del Package

```
packages/triple-persistence/
‚îú‚îÄ‚îÄ triple_persistence/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py              ‚úÖ YA CREADO
‚îÇ   ‚îú‚îÄ‚îÄ models.py                ‚úÖ YA CREADO (Pydantic schemas)
‚îÇ   ‚îú‚îÄ‚îÄ ingestion.py             ‚è≥ POR CREAR
‚îÇ   ‚îú‚îÄ‚îÄ retriever.py             ‚è≥ POR CREAR
‚îÇ   ‚îú‚îÄ‚îÄ neo4j_client.py          ‚è≥ POR CREAR
‚îÇ   ‚îú‚îÄ‚îÄ api.py                   ‚è≥ POR CREAR
‚îÇ   ‚îî‚îÄ‚îÄ cli.py                   ‚è≥ POR CREAR
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îú‚îÄ‚îÄ 01_simple_ingestion.py   ‚è≥ POR CREAR
‚îÇ   ‚îú‚îÄ‚îÄ 02_vector_search.py      ‚è≥ POR CREAR
‚îÇ   ‚îî‚îÄ‚îÄ 03_graph_traversal.py    ‚è≥ POR CREAR
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ test_ingestion.py        ‚è≥ POR CREAR
‚îú‚îÄ‚îÄ docker-compose.yml           ‚è≥ POR CREAR
‚îú‚îÄ‚îÄ Dockerfile                   ‚è≥ POR CREAR
‚îú‚îÄ‚îÄ requirements.txt             ‚úÖ YA CREADO
‚îî‚îÄ‚îÄ README.md                    ‚úÖ YA CREADO
```

---

### Paso 2.2: Ejemplo Simple 1 - Ingestion

**Archivo**: `examples/01_simple_ingestion.py`

```python
"""
Ejemplo 1: Ingestar un solo documento Markdown

Objetivo: Entender c√≥mo funciona el pipeline de ingesta
Tiempo: 5 minutos
"""

from triple_persistence.ingestion import TriplePersistencePipeline
from triple_persistence.models import IngestionConfig

# Configuraci√≥n
config = IngestionConfig(
    project="mi-primer-test",
    paths=["./data/ejemplo.md"],
    neo4j_uri="bolt://localhost:7687",
    neo4j_username="neo4j",
    neo4j_password="password",
    ollama_base_url="http://localhost:11434",
    embedding_model="nomic-embed-text",
    chunk_size=256  # Chunks peque√±os para este ejemplo
)

# Pipeline
pipeline = TriplePersistencePipeline(config)

# Ingestar
result = pipeline.ingest_directory(config.paths[0])

# Resultados
print(f"‚úÖ Documentos procesados: {result['documents_processed']}")
print(f"‚úÖ Chunks creados: {result['chunks_created']}")
print(f"‚úÖ Embeddings generados: {result['embeddings_generated']}")
print(f"‚è±Ô∏è Tiempo: {result['processing_time_seconds']}s")
```

**Ejecutar**:

```powershell
cd C:\proyectos\aleia-melquisedec\packages\triple-persistence

# Crear archivo de ejemplo
New-Item -ItemType Directory -Path "data" -Force
@"
# Mi Primer Documento

Este es un documento de prueba para triple-persistence.

## Secci√≥n 1
Contenido de la secci√≥n 1 con informaci√≥n relevante.

## Secci√≥n 2
M√°s contenido para generar chunks y embeddings.
"@ | Out-File -FilePath "data\ejemplo.md" -Encoding utf8

# Ejecutar ejemplo
python examples/01_simple_ingestion.py
```

**Output esperado**:
```
‚úÖ Documentos procesados: 1
‚úÖ Chunks creados: 3
‚úÖ Embeddings generados: 3
‚è±Ô∏è Tiempo: 2.4s
```

---

### Paso 2.3: Ejemplo Simple 2 - Vector Search

**Archivo**: `examples/02_vector_search.py`

```python
"""
Ejemplo 2: Buscar documentos con vector search

Objetivo: Ver c√≥mo funciona la b√∫squeda sem√°ntica
Tiempo: 3 minutos
"""

from triple_persistence.retriever import HybridRetriever
from triple_persistence.models import QueryRequest

# Configuraci√≥n
retriever = HybridRetriever(
    neo4j_uri="bolt://localhost:7687",
    neo4j_username="neo4j",
    neo4j_password="password",
    ollama_base_url="http://localhost:11434"
)

# Query
request = QueryRequest(
    query="¬øQu√© es triple-persistence?",
    top_k=3,
    include_graph=False  # Solo vector search
)

# Buscar
results = retriever.query(request)

# Mostrar resultados
print(f"üîç Query: {request.query}")
print(f"üìä Resultados: {len(results.results)}\n")

for i, result in enumerate(results.results, 1):
    print(f"{i}. {result.document_title}")
    print(f"   Similarity: {result.similarity_score:.3f}")
    print(f"   Excerpt: {result.excerpt[:100]}...")
    print()
```

**Output esperado**:
```
üîç Query: ¬øQu√© es triple-persistence?
üìä Resultados: 3

1. Mi Primer Documento
   Similarity: 0.847
   Excerpt: Este es un documento de prueba para triple-persistence...

2. ...
```

---

### Paso 2.4: Ejemplo Simple 3 - Graph Traversal

**Archivo**: `examples/03_graph_traversal.py`

```python
"""
Ejemplo 3: Enriquecer resultados con graph traversal

Objetivo: Ver c√≥mo el grafo mejora los resultados
Tiempo: 5 minutos
"""

from triple_persistence.retriever import HybridRetriever
from triple_persistence.models import QueryRequest

# Configuraci√≥n
retriever = HybridRetriever(
    neo4j_uri="bolt://localhost:7687",
    neo4j_username="neo4j",
    neo4j_password="password"
)

# Query con graph enrichment
request = QueryRequest(
    query="templates autopoi√©ticos",
    top_k=5,
    include_graph=True  # ‚Üê Activa graph traversal
)

# Buscar
results = retriever.query(request)

# Mostrar resultados enriquecidos
for result in results.results:
    print(f"üìÑ {result.document_title}")
    print(f"   Similarity: {result.similarity_score:.3f}")

    # Documentos relacionados (via graph)
    if result.related_documents:
        print(f"   üîó Referencias:")
        for related in result.related_documents:
            print(f"      - {related}")
    print()
```

**Output esperado**:
```
üìÑ PROPOSITO.md
   Similarity: 0.912
   üîó Referencias:
      - README.md
      - 010-define/requirements.md

üìÑ README.md
   Similarity: 0.854
   üîó Referencias:
      - PROPOSITO.md
```

---

## üîÑ Comparaci√≥n: GenAI Stack vs LlamaIndex MVP

| Caracter√≠stica | GenAI Stack | LlamaIndex MVP |
|----------------|-------------|----------------|
| **Setup** | 5 min | 1 semana |
| **Apps Incluidas** | 5 (bot, loader, PDF, API, UI) | Solo API |
| **Framework** | LangChain | LlamaIndex |
| **Tests** | ‚ùå No | ‚úÖ pytest |
| **Arquitectura** | Scripts | Hexagonal |
| **Docs** | Para StackOverflow Q&A | Para research docs |
| **Producci√≥n** | ‚ö†Ô∏è Demo-grade | ‚úÖ Production-ready |
| **Customizable** | ‚ö†Ô∏è Hardcoded | ‚úÖ Config-driven |
| **Aprendizaje** | ‚ö° Inmediato | üìö Progresivo |

---

## üéì Learning Path (Ruta de Aprendizaje)

### D√≠a 1: GenAI Stack
- ‚úÖ Instalar y configurar
- ‚úÖ Ver Neo4j Browser funcionando
- ‚úÖ Probar chatbot de ejemplo
- ‚úÖ Inspeccionar Cypher queries

### D√≠a 2-3: LlamaIndex Basics
- ‚è≥ Ejecutar ejemplo 01 (ingestion)
- ‚è≥ Ejecutar ejemplo 02 (vector search)
- ‚è≥ Ejecutar ejemplo 03 (graph traversal)
- ‚è≥ Modificar par√°metros y experimentar

### D√≠a 4-5: Implementaci√≥n
- ‚è≥ Completar ingestion.py
- ‚è≥ Completar retriever.py
- ‚è≥ Crear tests

### D√≠a 6-7: Integraci√≥n
- ‚è≥ Ingestar research-autopoietic-template
- ‚è≥ Validar success criteria
- ‚è≥ Documentar workflows

---

## üêõ Troubleshooting (Problemas Comunes)

### Problema 1: Neo4j no inicia

```powershell
# Verificar logs
docker logs genai-stack-database-1

# Error com√∫n: Puerto 7687 ocupado
# Soluci√≥n: Detener Neo4j existente
Get-Process | Where-Object {$_.ProcessName -like "*neo4j*"} | Stop-Process
```

### Problema 2: Ollama no conecta

```powershell
# Verificar Ollama corriendo
ollama list

# Si no responde, reiniciar
# En Windows: Restart Ollama desde system tray

# Verificar puerto
Test-NetConnection -ComputerName localhost -Port 11434
```

### Problema 3: Embeddings muy lentos

```bash
# Soluci√≥n 1: Usar modelo m√°s peque√±o
EMBEDDING_MODEL=all-minilm-l6-v2  # 384 dim vs 768

# Soluci√≥n 2: Batch processing
chunk_size=128  # Chunks m√°s peque√±os
```

### Problema 4: Docker "out of memory"

```powershell
# Aumentar RAM en Docker Desktop
# Settings ‚Üí Resources ‚Üí Memory ‚Üí 8GB m√≠nimo
```

---

## üìö Recursos Adicionales

### Documentaci√≥n Oficial
- GenAI Stack: https://github.com/docker/genai-stack
- LlamaIndex: https://docs.llamaindex.ai
- Neo4j Vector: https://neo4j.com/docs/cypher-manual/current/indexes/semantic-indexes/
- Ollama: https://ollama.ai/library

### Tutoriales Recomendados
1. Neo4j Cypher Basics: https://neo4j.com/graphacademy/
2. LlamaIndex Tutorials: https://docs.llamaindex.ai/en/stable/getting_started/
3. RAG Architecture: https://www.youtube.com/watch?v=T-D1OfcDW1M

### Papers Relevantes
- GraphRAG (Microsoft Research, 2024)
- Neo4j Vector Index (Neo4j Labs, 2023)

---

## üéØ Success Criteria

**Has completado exitosamente el quickstart si**:

‚úÖ GenAI Stack:
- [ ] Neo4j Browser abierto y funcionando
- [ ] Chatbot cargando y respondiendo queries
- [ ] Vector search retornando resultados

‚úÖ LlamaIndex MVP:
- [ ] Ejemplo 01 ejecutado correctamente
- [ ] Ejemplo 02 retornando similarity > 0.7
- [ ] Ejemplo 03 mostrando related_documents

‚úÖ Comprensi√≥n:
- [ ] Entiendes diferencia entre Graph y Vector
- [ ] Sabes cu√°ndo usar GenAI Stack vs LlamaIndex MVP
- [ ] Puedes explicar Triple-Persistence a un colega

---

**Pr√≥ximos Pasos**: Ver `mvp-triple-persistence.md` para arquitectura completa

**Ayuda**: Si te atascas, revisar Troubleshooting o consultar documentaci√≥n oficial
