# HITO 3 - Implementation & POC Integration (PARA DUMMIES)

**Version**: 0.1.0  
**Status**: In Progress  
**Last Updated**: 2026-01-12

---

## ğŸ¯ Â¿QuÃ© estamos haciendo?

**AnalogÃ­a**: Si HITO 2 fue preparar las recetas y moldes, HITO 3 es **instalar el robot de calidad** que verifica automÃ¡ticamente que cada pizza salga perfecta.

### Los 4 Productos Principales

1. **CI/CD Pipeline** (El Robot Inspector) ğŸ¤–
   - Verifica automÃ¡ticamente cada cambio
   - Ejecuta 3 tipos de tests: ROBOT, SHACL, SPARQL
   - Genera reportes con badges (âœ… PASS / âŒ FAIL)

2. **Validation Scripts** (Las 3 Estaciones de Control) ğŸ”
   - ROBOT: Verifica axiomas OWL (consistencia lÃ³gica)
   - pySHACL: Valida instancias (reglas de negocio)
   - SPARQL: Ejecuta CQs (responde preguntas)

3. **PyKEEN Experiment** (Experimento de Similitud) ğŸ§ª
   - Genera embeddings (vectores numÃ©ricos)
   - Predice relaciones (link prediction)
   - EvalÃºa calidad (Hits@10, Mean Rank)

4. **Documentation** (Manual del Robot) ğŸ“š
   - README-HITO3.md (esta guÃ­a)
   - Setup instructions
   - Troubleshooting guide

---

## ğŸ• AnalogÃ­a: La LÃ­nea de Control de Calidad

Imagina que tu pizzerÃ­a ahora tiene 3 inspectores automÃ¡ticos:

### Inspector 1: ROBOT (El LÃ³gico) ğŸ§ 
- **Pregunta**: "Â¿La receta tiene sentido matemÃ¡ticamente?"
- **Verifica**: 
  - Â¿Un libro puede ser Y NO SER una revista al mismo tiempo? (disjointness)
  - Â¿Si algo es FicciÃ³n, automÃ¡ticamente es CategorÃ­a? (subclass inference)
  - Â¿Las propiedades tienen dominio y rango correctos?
- **Resultado**: Report HTML con errores/warnings

### Inspector 2: pySHACL (El Estricto) ğŸ“‹
- **Pregunta**: "Â¿Las pizzas cumplen las reglas del negocio?"
- **Verifica**:
  - Â¿Cada Libro tiene exactamente 1 ISBN?
  - Â¿Cada PrÃ©stamo tiene fecha de inicio y fin?
  - Â¿Los valores son del tipo correcto (string, date, etc.)?
- **Resultado**: Lista de violaciones con ubicaciÃ³n exacta

### Inspector 3: SPARQL (El Funcional) âœ…
- **Pregunta**: "Â¿El sistema responde correctamente a las preguntas?"
- **Verifica**:
  - CQ1: "Â¿QuÃ© libros escribiÃ³ GarcÃ­a MÃ¡rquez?" â†’ [CienAÃ±osDeSoledad, AmorEnTiemposDelColera]
  - CQ2: "Â¿QuiÃ©n prestÃ³ '1984'?" â†’ [Usuario123]
  - CQ3: "Â¿CuÃ¡ntos prÃ©stamos activos hay?" â†’ [2]
- **Resultado**: Pass rate (% de CQs que pasaron)

---

## ğŸ”„ Flujo Completo (7 Pasos)

```
1. Developer hace cambio â†’ 2. Git push â†’ 3. GitHub Actions trigger
                                              â†“
4. CI/CD corre 3 validaciones (ROBOT + pySHACL + SPARQL)
                                              â†“
5. Genera reportes â†’ 6. Badges actualizados â†’ 7. Email si falla
```

**Tiempo**: ~5 minutos por ejecuciÃ³n (automatizado)

---

## ğŸ“¦ Lo que vamos a construir

### Estructura de carpetas

```
hito-3-implementacion/
â”œâ”€â”€ README-HITO3.md (esta guÃ­a)
â”œâ”€â”€ ci-cd/
â”‚   â”œâ”€â”€ .github/workflows/ontology-validation.yml (pipeline GitHub Actions)
â”‚   â””â”€â”€ badges/ (generated badges: validation-pass.svg)
â”œâ”€â”€ validation-scripts/
â”‚   â”œâ”€â”€ run_robot.sh (ROBOT validation)
â”‚   â”œâ”€â”€ run_shacl.py (pySHACL validation)
â”‚   â”œâ”€â”€ run_sparql_tests.py (CQ execution)
â”‚   â””â”€â”€ requirements.txt (Python deps)
â”œâ”€â”€ shacl-shapes/
â”‚   â”œâ”€â”€ concept-shapes.ttl (reglas para conceptos)
â”‚   â”œâ”€â”€ relation-shapes.ttl (reglas para relaciones)
â”‚   â””â”€â”€ instance-shapes.ttl (reglas para instancias)
â”œâ”€â”€ embedding-experiment/
â”‚   â”œâ”€â”€ pykeen_config.yaml (configuraciÃ³n TransE)
â”‚   â”œâ”€â”€ train_embeddings.py (script entrenamiento)
â”‚   â”œâ”€â”€ evaluate_embeddings.py (mÃ©tricas)
â”‚   â””â”€â”€ results/ (output: vectores, grÃ¡ficos t-SNE)
â””â”€â”€ reports/ (generated)
    â”œâ”€â”€ robot-report.html
    â”œâ”€â”€ shacl-report.txt
    â”œâ”€â”€ sparql-results.json
    â””â”€â”€ pykeen-metrics.json
```

---

## ğŸš€ CÃ³mo funciona el CI/CD

### Workflow GitHub Actions (simplificado)

```yaml
name: Ontology Validation

on: [push, pull_request]

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - Checkout code
      - Install ROBOT (Java)
      - Install pySHACL (Python)
      - Install SPARQL engine (Apache Jena ARQ)
      
      - Run ROBOT validation
      - Run pySHACL validation
      - Run SPARQL tests
      
      - Upload reports
      - Update badges
      - Notify on failure
```

### Â¿CuÃ¡ndo se ejecuta?

- âœ… Cada push a feature/spec-001-implementation
- âœ… Cada pull request a main
- âœ… Manualmente desde GitHub UI
- âŒ NO se ejecuta en commits locales (solo en GitHub)

---

## ğŸ§ª PyKEEN Embedding Experiment

### Â¿QuÃ© son embeddings?

**AnalogÃ­a**: Convierte conceptos en coordenadas GPS.

- Libro â†’ [0.8, 0.3, -0.1, 0.5, ...] (vector de 100 dimensiones)
- Autor â†’ [0.7, 0.4, 0.0, 0.6, ...]

**Ventaja**: Puedes medir "distancia semÃ¡ntica":
- `distance(Libro, Autor)` = 0.2 (muy relacionados)
- `distance(Libro, Usuario)` = 0.7 (menos relacionados)

### Casos de uso

1. **Link Prediction**: "Si CienAÃ±osDeSoledad â†’ hasAutor â†’ Â¿?, predice GGMarquez"
2. **Semantic Search**: "Encuentra conceptos similares a 'PrÃ©stamo'"
3. **Clustering**: "Agrupa libros por temÃ¡tica automÃ¡ticamente"

### MÃ©tricas de EvaluaciÃ³n

- **Hits@10**: Â¿El concepto correcto estÃ¡ en el top 10? (target: >80%)
- **Mean Rank**: PosiciÃ³n promedio del correcto (target: <50)
- **MRR** (Mean Reciprocal Rank): 1/posiciÃ³n (target: >0.5)

---

## ğŸ“Š Checklist de Progreso

### Fase 1: Setup (2h)
- [ ] Crear estructura de carpetas
- [ ] Instalar herramientas localmente (ROBOT, pySHACL, ARQ)
- [ ] Configurar GitHub Actions secrets (si aplica)

### Fase 2: Validation Scripts (6h)
- [ ] Script ROBOT con reporte HTML
- [ ] SHACL shapes para 5 conceptos clave (Libro, Autor, PrÃ©stamo, Usuario, CategorÃ­a)
- [ ] Script pySHACL con output JSON
- [ ] AutomatizaciÃ³n SPARQL tests (5 CQs)

### Fase 3: CI/CD Pipeline (4h)
- [ ] Workflow YAML completo
- [ ] Badge generation (shields.io)
- [ ] Email notifications (GitHub Actions)
- [ ] Test ejecuciÃ³n en PR de prueba

### Fase 4: PyKEEN Experiment (8h)
- [ ] Config TransE model (100 dims, 500 epochs)
- [ ] Script entrenamiento con logging
- [ ] EvaluaciÃ³n mÃ©tricas (Hits@10, MR, MRR)
- [ ] t-SNE visualization (2D plot)
- [ ] Report experiment results

### Fase 5: Documentation (2h)
- [ ] README-HITO3.md (esta guÃ­a) âœ…
- [ ] Setup instructions por OS (Windows, Linux, Mac)
- [ ] Troubleshooting common errors
- [ ] Update main README status

**Total estimado**: 22 horas (~3 dÃ­as)

---

## ğŸ› ï¸ Herramientas y Dependencias

### ROBOT (OWL Validation)
```bash
# Install (requiere Java 11+)
wget https://github.com/ontodev/robot/releases/download/v1.9.5/robot.jar
java -jar robot.jar --version
```

### pySHACL (Constraint Validation)
```bash
pip install pyshacl rdflib
pyshacl --version
```

### Apache Jena ARQ (SPARQL Engine)
```bash
wget https://dlcdn.apache.org/jena/binaries/apache-jena-4.10.0.tar.gz
tar -xzf apache-jena-4.10.0.tar.gz
export PATH=$PATH:$(pwd)/apache-jena-4.10.0/bin
arq --version
```

### PyKEEN (Knowledge Graph Embeddings)
```bash
pip install pykeen torch
pykeen --version
```

---

## ğŸ“ Glosario TÃ©cnico

| TÃ©rmino | DefiniciÃ³n | AnalogÃ­a |
|---------|-----------|----------|
| **CI/CD** | Continuous Integration/Deployment | Robot que revisa cada cambio automÃ¡ticamente |
| **ROBOT** | OWL validation tool | Inspector de lÃ³gica matemÃ¡tica |
| **pySHACL** | SHACL validator | Inspector de reglas de negocio |
| **SPARQL** | RDF query language | Lenguaje para preguntas a la base de datos |
| **Hits@10** | Top-10 accuracy | Â¿La respuesta correcta estÃ¡ en las primeras 10? |
| **Mean Rank** | Average position | PosiciÃ³n promedio de la respuesta correcta |
| **TransE** | Translation embedding model | Modelo que aprende: Libro + hasAutor = Autor |
| **t-SNE** | Dimensionality reduction | ProyecciÃ³n de 100D a 2D para visualizaciÃ³n |

---

## ğŸ§‘â€ğŸ’¼ Roles y Responsabilidades

### DevOps Engineer (tÃº, con apoyo de Copilot)
- Configurar GitHub Actions workflow
- Instalar herramientas localmente
- Debuggear fallos de CI/CD
- Mantener badges actualizados

### Ontology Engineer (equipo)
- Crear SHACL shapes rigurosos
- Validar reportes ROBOT
- Ajustar axiomas si hay inconsistencias
- Revisar false positives

### Data Scientist (equipo, opcional)
- Configurar PyKEEN hyperparameters
- Interpretar mÃ©tricas de embeddings
- Generar visualizaciones
- Proponer mejoras de modelo

### Domain Expert (equipo)
- Validar que CQs representen casos reales
- Revisar violaciones SHACL (Â¿son errores reales?)
- Aprobar resultados de experimento

---

## â“ FAQs - HITO 3

### 1. Â¿Por quÃ© necesitamos 3 validadores diferentes?
Cada uno verifica un aspecto distinto:
- ROBOT: LÃ³gica (matemÃ¡ticas)
- pySHACL: Reglas (negocio)
- SPARQL: Funcionalidad (casos de uso)

### 2. Â¿QuÃ© pasa si una validaciÃ³n falla?
- El CI/CD marca el commit como âŒ FAILED
- Se genera un reporte con el error especÃ­fico
- No se puede mergear a main hasta que se arregle

### 3. Â¿Puedo correr las validaciones localmente?
SÃ­, con los scripts en `validation-scripts/`:
```bash
./run_robot.sh
python run_shacl.py
python run_sparql_tests.py
```

### 4. Â¿QuÃ© hacer si el embedding experiment da mÃ©tricas bajas?
- Aumentar epochs (500 â†’ 1000)
- Cambiar modelo (TransE â†’ DistMult)
- Agregar mÃ¡s triples de entrenamiento
- Consultar con Data Scientist

### 5. Â¿CuÃ¡nto tarda el CI/CD en ejecutarse?
- ROBOT: ~30 segundos
- pySHACL: ~20 segundos
- SPARQL: ~10 segundos
- **Total**: ~1-2 minutos

### 6. Â¿DÃ³nde se guardan los reportes?
- En GitHub Actions: Artifacts tab
- Localmente: carpeta `reports/`
- En commits: badges en README.md

### 7. Â¿QuÃ© es un "embedding vector"?
Es una lista de nÃºmeros que representa un concepto:
```python
lib:Libro â†’ [0.8, 0.3, -0.1, 0.5, ..., 0.2]  # 100 nÃºmeros
```
El modelo aprende estos nÃºmeros para que conceptos relacionados estÃ©n cerca.

### 8. Â¿Por quÃ© TransE y no otro modelo?
TransE es simple y rÃ¡pido para POCs. Otros modelos (DistMult, ComplEx) son mÃ¡s precisos pero requieren mÃ¡s datos y tiempo.

### 9. Â¿CÃ³mo interpreto Hits@10 = 0.87?
Significa que el 87% de las veces, la respuesta correcta estÃ¡ en el top 10 de predicciones. Es una mÃ©trica excelente (>80%).

### 10. Â¿QuÃ© hacemos despuÃ©s de HITO 3?
HITO 4: Deployment & Monitoring (producciÃ³n real con Biblioteca)

---

## ğŸ”— Referencias Cruzadas

- **HITO 1**: [README-HITO1.md](../hito-1-analisis/README-HITO1.md) - AnÃ¡lisis de gaps
- **HITO 2**: [README-HITO2.md](../hito-2-conceptualizacion/README-HITO2.md) - Templates y OTTR
- **Main README**: [README.md](../README.md) - Overview del proyecto
- **GuÃ­a Dummies**: [00-GUIA-PARA-DUMMIES.md](../00-GUIA-PARA-DUMMIES.md) - AnalogÃ­as generales

---

## ğŸ“ Documentos de HITO 3

1. **README-HITO3.md** (esta guÃ­a) - Overview para dummies
2. **ontology-validation.yml** - GitHub Actions workflow
3. **run_robot.sh** - Script validaciÃ³n ROBOT
4. **run_shacl.py** - Script validaciÃ³n pySHACL
5. **run_sparql_tests.py** - AutomatizaciÃ³n CQs
6. **concept-shapes.ttl** - SHACL shapes para conceptos
7. **pykeen_config.yaml** - ConfiguraciÃ³n embeddings
8. **train_embeddings.py** - Script entrenamiento PyKEEN
9. **evaluate_embeddings.py** - MÃ©tricas y visualizaciÃ³n

---

## ğŸ¯ Objetivos de Aprendizaje

Al completar HITO 3, habrÃ¡s aprendido:

âœ… CÃ³mo configurar un pipeline CI/CD para ontologÃ­as  
âœ… Diferencia entre validaciÃ³n OWL, SHACL y SPARQL  
âœ… CÃ³mo automatizar tests de competency questions  
âœ… QuÃ© son embeddings y cÃ³mo generarlos  
âœ… CÃ³mo interpretar mÃ©tricas de link prediction  
âœ… Best practices de DevOps para proyectos de ontologÃ­as

---

**Â¿Listo para empezar?** â†’ ContinÃºa con [Setup Instructions](setup-instructions.md)

**Â¿Te perdiste?** â†’ Vuelve a [00-GUIA-PARA-DUMMIES.md](../00-GUIA-PARA-DUMMIES.md)
