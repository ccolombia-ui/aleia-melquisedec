# Architecture Best Practices v1.0.0 - Requirements

## Overview

Este spec implementa arquitectura √≥ptima para Triple Persistencia MELQUISEDEC basada en an√°lisis profundo de 34 papers acad√©micos, documentaci√≥n oficial de Neo4j, y c√≥digo de Obsidian Smart Connections. Resuelve 4 gaps cr√≠ticos identificados (G1-G4) para establecer fundamentos s√≥lidos antes de desarrollo.

**Premisa clave**: NO hay que migrar nada (no existe implementaci√≥n previa), solo documentar y crear la arquitectura correcta desde el inicio.

---

## User Stories

### US-1: Como arquitecto, quiero que los vectores embeddings est√©n en Neo4j (no Redis)
- Para tener queries unificadas (graph + vectors en 1 query)
- Para eliminar complejidad de dual storage
- Para aprovechar Neo4j Vector Index nativo (HNSW)
- **Relacionado**: Gap G1

### US-2: Como desarrollador, quiero un pipeline documentado para procesar documentos
- Para entender c√≥mo Markdown ‚Üí Chunks ‚Üí Embeddings ‚Üí Storage
- Para debugging cuando embeddings no son correctos
- Para onboarding de nuevos contribuidores
- **Relacionado**: Gap G2

### US-3: Como desarrollador, quiero entender el schema de Autopoiesis en Neo4j
- Para consultar la evoluci√≥n de domains y lessons
- Para extender el schema con nuevos nodos
- Para troubleshooting cuando queries fallan
- **Relacionado**: Gap G3

### US-4: Como architect, quiero benchmarks que validen la arquitectura
- Para tomar decisiones basadas en datos (no opiniones)
- Para comparar vs alternativas (Smart Connections)
- Para detectar regresiones de performance
- **Relacionado**: Gap G4

---

## Functional Requirements

### REQ-1: Neo4j Vector Index (Eliminar Redis para vectores)

**Objetivo**: Usar Neo4j 5.15.0+ native vector index en lugar de dual storage.

**Criterios de aceptaci√≥n**:
1. ‚úÖ Crear vector index en Neo4j con Cypher:
   ```cypher
   CREATE VECTOR INDEX melquisedec_embeddings IF NOT EXISTS
   FOR (n:DocumentChunk)
   ON n.embedding
   OPTIONS {
     indexConfig: {
       `vector.dimensions`: 1536,
       `vector.similarity_function`: 'cosine',
       `vector.quantization.enabled`: true
     }
   }
   ```

2. ‚úÖ Actualizar `docker-compose.yml`:
   - Mantener Neo4j con plugins APOC + GDS
   - Mantener Ollama para embeddings locales
   - **NO** incluir Redis para vector store (solo si se usa para otra cosa)

3. ‚úÖ Documentar query pattern:
   ```cypher
   // Query h√≠brida: graph + vectors en 1 sola query
   MATCH (n:Spec)-[:HAS_ISSUE]->(i:Issue)
   CALL db.index.vector.queryNodes('melquisedec_embeddings', 5, $queryVector)
   YIELD node, score
   WHERE node = n
   RETURN i, score
   ORDER BY score DESC
   ```

**Validaci√≥n**:
- `SHOW INDEXES` en Neo4j muestra vector index
- `docker ps` **no** muestra Redis container para vectores
- Query de ejemplo retorna resultados con scores

**Priority**: üî¥ **ALTA** - Fundamento arquitect√≥nico

---

### REQ-2: Pipeline Formal de Procesamiento de Documentos

**Objetivo**: Implementar y documentar pipeline LlamaIndex + Semantic Chunking.

**Criterios de aceptaci√≥n**:
1. ‚úÖ Crear `packages/daath-toolkit/processors/document_pipeline.py` con clase `MELQUISEDECPipeline`:
   - **Fase 1**: Document Loading (SimpleDirectoryReader)
   - **Fase 2**: Statistical Analysis (language detection, complexity score)
   - **Fase 3**: Semantic Chunking (MarkdownNodeParser, 512 tokens, overlap 100)
   - **Fase 4**: Embedding (Ollama qwen3-embedding)
   - **Fase 5**: Storage (Neo4j Vector Index + Knowledge Graph)

2. ‚úÖ Instalar dependencias:
   ```bash
   pip install llama-index llama-index-vector-stores-neo4j llama-index-embeddings-ollama
   ```

3. ‚úÖ Crear documentaci√≥n `docs/manifiesto/04-implementacion/06-pipeline-document-processing.md`:
   - Diagrama de fases
   - C√≥digo de ejemplo
   - Par√°metros configurables (chunk_size, overlap, modelo embedding)
   - Troubleshooting com√∫n

4. ‚úÖ Integrar con KnowledgeWriter (si existe):
   ```python
   class KnowledgeWriter:
       def __init__(self):
           self.pipeline = MELQUISEDECPipeline()
       
       def write_atomically(self, file_paths: List[str], metadata: Dict):
           index = self.pipeline.process_documents(file_paths, metadata)
           return index
   ```

**Validaci√≥n**:
- Archivo `document_pipeline.py` existe y tiene clase completa
- Doc `06-pipeline-document-processing.md` tiene ‚â•400 l√≠neas
- Tests b√°sicos en `packages/daath-toolkit/testing/test_document_pipeline.py` pasan

**Priority**: üî¥ **ALTA** - Sin pipeline no hay consistencia

---

### REQ-3: Actualizar Configuraci√≥n Docker (Sin Redis para vectores)

**Objetivo**: Actualizar `infrastructure/docker/docker-compose.yml` con configuraci√≥n correcta.

**Criterios de aceptaci√≥n**:
1. ‚úÖ Mantener **solo** Neo4j + Ollama:
   ```yaml
   services:
     neo4j:
       image: neo4j:5.15-community
       # ... config con APOC + GDS
     
     ollama:
       image: ollama/ollama:latest
       # ... config
     
     # NO Redis para vectores (a menos que se use para cache/sessions)
   ```

2. ‚úÖ Neo4j environment variables:
   - `NEO4J_PLUGINS=["apoc", "graph-data-science"]`
   - `NEO4J_dbms_memory_heap_max__size=2G` (suficiente para vectors)
   - `NEO4J_dbms_security_procedures_unrestricted=apoc.*,gds.*`

3. ‚úÖ Actualizar `docs/manifiesto/04-implementacion/04-memoria-y-persistencia-triple.md`:
   - Remover referencias a Redis vector store
   - Actualizar diagrams (solo Neo4j + Ollama)
   - Actualizar c√≥digo de ejemplo (sin redis_client)

**Validaci√≥n**:
- `docker-compose up -d` inicia solo Neo4j + Ollama
- `docker ps | grep redis` retorna vac√≠o (o Redis para otra cosa, no vectores)
- Doc `04-memoria-y-persistencia-triple.md` no menciona Redis para embeddings

**Priority**: üü† **MEDIA** - Dependencia de REQ-1

---

### REQ-4: Documentar Schema de Autopoiesis

**Objetivo**: Explicar el schema Neo4j existente (`tools/setup/neo4j_schema.py`).

**Criterios de aceptaci√≥n**:
1. ‚úÖ Crear ADR `docs/manifiesto/02-arquitectura/ADR-002-neo4j-unified-architecture.md`:
   - Context: Por qu√© usar Neo4j para graph + vectors
   - Decision: Arquitectura unificada (no dual storage)
   - Consequences: Ventajas (queries simples) y trade-offs (latencia ligeramente mayor)

2. ‚úÖ Crear doc `docs/manifiesto/02-arquitectura/06-schema-autopoiesis.md`:
   - TL;DR del schema
   - Diagrama Mermaid de nodos y relaciones
   - Descripci√≥n de cada nodo: Domain, ResearchInstance, Lesson, PromptType, Output
   - Constraints e √≠ndices
   - Queries frecuentes con ejemplos
   - Uso desde Python (`neo4j_schema.py`)

3. ‚úÖ Actualizar README principal con enlace al schema doc

**Validaci√≥n**:
- Archivos ADR-002 y 06-schema-autopoiesis.md existen
- Doc tiene ‚â•600 l√≠neas con diagrams + code
- README principal lista estos docs en secci√≥n "Arquitectura"

**Priority**: üü° **MEDIA** - Documentaci√≥n importante pero no bloqueante

---

### REQ-5: Suite de Benchmarking

**Objetivo**: Crear framework para validar arquitectura vs alternativas.

**Criterios de aceptaci√≥n**:
1. ‚úÖ Crear dataset de test:
   ```python
   # packages/daath-toolkit/testing/fixtures/test_notes_100.json
   {
       "notes": [
           {
               "id": "note-001",
               "content": "...",
               "ground_truth_connections": ["note-045", "note-078"]
           },
           # ... 99 more
       ]
   }
   ```

2. ‚úÖ Implementar `benchmark_vs_smart_connections.py`:
   - Clase `ConnectionsBenchmark`
   - M√©tricas: Precision@k, Recall@k, MRR (Mean Reciprocal Rank), Latency
   - Comparaci√≥n: MELQUISEDEC (embeddings only) vs MELQUISEDEC (graph + embeddings) vs Smart Connections (baseline simulado)

3. ‚úÖ Ejecutar benchmarks y documentar resultados:
   ```bash
   pytest packages/daath-toolkit/testing/benchmark_vs_smart_connections.py --benchmark
   ```

4. ‚úÖ Crear doc `docs/manifiesto/04-implementacion/07-benchmark-results.md`:
   - Tabla de resultados
   - Interpretaci√≥n (MELQUISEDEC graph+embeddings debe superar Smart Connections)
   - Gr√°ficos (opcional)

**Validaci√≥n**:
- Archivo `benchmark_vs_smart_connections.py` existe
- Dataset `test_notes_100.json` tiene 100 notas con ground truth
- Benchmark ejecuta en <5 minutos
- Doc con resultados muestra Precision@10 ‚â• 0.75 para MELQUISEDEC

**Priority**: üü¢ **BAJA** - Validaci√≥n √∫til pero no cr√≠tica

---

### REQ-6: Actualizar Documentos Existentes

**Objetivo**: Actualizar docs que referencian arquitectura antigua.

**Archivos a actualizar**:
1. ‚úÖ `docs/manifiesto/04-implementacion/04-memoria-y-persistencia-triple.md`:
   - Remover secciones de Redis para vectores
   - Actualizar diagramas (solo Neo4j + Ollama)
   - Actualizar c√≥digo Python (eliminar `redis_client.json()`)

2. ‚úÖ `docs/manifiesto/04-implementacion/05-analisis-arquitectura-best-practices.md`:
   - Marcar G1 (Dual Vector Storage) como **RESUELTO**
   - Marcar G2 (Undocumented Pipeline) como **RESUELTO**
   - Agregar secci√≥n "Implementation Status" al final

3. ‚úÖ `docs/guides/configuracion-completa.md` (si existe):
   - Actualizar pasos de setup (sin Redis para vectores)
   - Actualizar docker-compose commands

4. ‚úÖ `docs/guides/quick-reference.md` (si existe):
   - Actualizar quick start (docker-compose con solo Neo4j + Ollama)

**Validaci√≥n**:
- Grep search `grep -r "Redis.*vector\|vector.*Redis" docs/` retorna 0 resultados (excepto en contexto hist√≥rico)
- Docs mencionan "Neo4j Vector Index nativo"

**Priority**: üü† **MEDIA** - Evita confusi√≥n

---

## Non-Functional Requirements

### NFR-1: Performance
- Neo4j vector queries deben responder en <100ms para k=10
- Pipeline debe procesar 100 documentos en <2 minutos
- Benchmarks deben ejecutar en <5 minutos

### NFR-2: Maintainability
- C√≥digo debe tener docstrings completos (Google style)
- Pipeline debe ser extensible (f√°cil agregar nuevas fases)
- Configuraci√≥n debe ser centralizada (no hardcoded)

### NFR-3: Documentaci√≥n
- Cada doc debe tener TL;DR al inicio
- Diagramas Mermaid para arquitectura
- Code examples ejecutables (no pseudoc√≥digo)

### NFR-4: Compatibility
- Python 3.11+
- Neo4j 5.15+
- LlamaIndex 0.10.0+

---

## Priority Order

1. **üî¥ Alta**: REQ-1 (Neo4j vectors), REQ-2 (Pipeline), REQ-3 (Docker) - Fundamentos
2. **üü† Media**: REQ-4 (Schema docs), REQ-6 (Update docs) - Documentaci√≥n cr√≠tica
3. **üü¢ Baja**: REQ-5 (Benchmarks) - Validaci√≥n nice-to-have

---

## Success Criteria

- [ ] Todos los REQs 1-4 implementados y validados
- [ ] REQ-5 implementado (benchmarks) al menos con baseline
- [ ] REQ-6 completado (docs actualizados)
- [ ] Todos los NFRs cumplidos
- [ ] CHANGELOG.md actualizado con v1.0.0
- [ ] Dashboard spec-workflow muestra 100% completado

---

## Out of Scope

‚ùå **NO incluido en este spec**:
- Implementaci√≥n de UI/dashboard (futuro spec)
- Integraci√≥n con KETER (spec separado existente)
- Tests unitarios exhaustivos (solo benchmarks b√°sicos)
- Performance tuning avanzado (solo configuraci√≥n inicial)
- Multimodal embeddings (solo text por ahora)

---

## Dependencies

- **Spec previo**: `monorepo-improvements` (debe estar completo)
- **Docs existentes**: `05-analisis-arquitectura-best-practices.md` (referencia de investigaci√≥n)
- **C√≥digo existente**: `tools/setup/neo4j_schema.py` (ya existe, no modificar)

---

## Risks & Mitigations

| Risk | Impact | Mitigation |
|------|--------|------------|
| Neo4j vector index no rinde | ALTO | Benchmark early, comparar con Redis si es necesario |
| LlamaIndex breaking changes | MEDIO | Pin versiones en requirements.txt |
| Semantic chunking produce chunks muy grandes | MEDIO | Tuning de chunk_size (512, 768, 1024) |
| Benchmarks no son representativos | BAJO | Validar dataset con expertos |

---

**Versi√≥n**: 1.0.0
**√öltima actualizaci√≥n**: 2026-01-08
**Rostro autor**: SALOMON (Architect)
