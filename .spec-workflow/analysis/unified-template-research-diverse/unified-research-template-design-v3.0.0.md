# Unified Research Template v3.0.0 - Design Specification

> **Version**: 3.0.0 (Consolidated from 5 analysis documents)
> **Date**: 2026-01-09
> **Purpose**: Template unificado definitivo - INTEGRA estÃ¡ndares existentes
> **Status**: âœ… Final Design - Ready for Implementation
> **Consolidated from**:
> - coherence-index-analysis-2026-01-09.md
> - consolidation-spec-workflow-daath-zen.md
> - deep-coherence-analysis-2026-01-09.md
> - unified-research-template-design-v2.0.0.md
> - gap-analysis-unified-template-2026-01-09.md

---

## ğŸ¯ Executive Summary

### Evolution of Design

| Version | Approach | Critical Issue | Resolution |
|---------|----------|----------------|------------|
| **v1.0.0** | DiseÃ±ar versionado desde cero | âŒ Reinventa HKM/keterdoc existente | Descartado |
| **v2.0.0** | Integrar HKM + stack hÃ­brido | âš ï¸ Demasiado extenso (1351 lÃ­neas) | Refactorizado |
| **v3.0.0** | ConsolidaciÃ³n definitiva | âœ… SÃ­ntesis de 5 anÃ¡lisis | **FINAL** |

### Key Decisions

```yaml
decisions:
  versionado: "USAR HKM/keterdoc existente (NO reinventar)"
  stack: "USAR arquitectura hÃ­brida validada (LlamaIndex + LangChain + Neo4j)"
  task_format: "ADOPTAR DAATH-ZEN Advanced (archive/tasks.md, 95% coherencia)"
  workflows: "DIVERGIR post-SALOMON (research/app/social-project)"
  principios: "OPERACIONALIZAR P1-P7 con ejemplos ejecutables"
```

### Deliverables

```
unified-research-template-v3.0.0/
â”œâ”€â”€ ISSUE.yaml.template              # Epic metadata
â”œâ”€â”€ tasks.md.template                # DAATH-ZEN Advanced format
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ sync-hkm-to-neo4j.py         # MD â†’ Graph sync
â”‚   â”œâ”€â”€ archive-epic.sh              # Git tag + soft delete
â”‚   â””â”€â”€ validate-triple-coherence.py # MD â†” Graph â†” Vector
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ research-example-v1.0.0/     # Complete working example
â””â”€â”€ docs/
    â”œâ”€â”€ workflows-divergentes.md     # Research/App/Social paths
    â””â”€â”€ principios-operacionalizados.md # P1-P7 with examples
```

---

## ğŸ“š Part 1: Fundamentos (Standards Already Existing)

### 1.1 HKM/Keterdoc Standard (DO NOT REINVENT)

**Source**: `docs/manifiesto/02-arquitectura/03-templates-hkm.md`

```yaml
---
# IdentificaciÃ³n
id: "unique-identifier-kebab-case"
is_a: "source|concept|workbook|artifact|output|lesson"
version: "1.0.0"

# Dublin Core (ISO 15836)
dc:
  title: "Descriptive title"
  creator: ["HYPATIA"]
  date: "2026-01-09"
  subject: ["tag1", "tag2"]
  description: "Brief summary"
  source: ["DOI", "URL"]

# SECI Model (traceability)
seci:
  derives_from: ["../source-01.md"]
  informs: ["../derivative-01.md"]

# Lifecycle
status: "draft|published|archived"
git_tag: "output-v1.0.0"
---
```

**Validation**: `validate-metadata.py` (already exists)

**Neo4j Integration**:
- `id` â†’ Node property
- `seci.derives_from` â†’ `[:DERIVES_FROM]` relationship
- `version` â†’ Node property for rollback

### 1.2 Hybrid Stack (ALREADY VALIDATED)

**Source**: `apps/research-neo4j-llamaindex-architecture/01-design/state-of-art/comparative-analysis.md`

| Framework | Score | Role | Justification |
|-----------|-------|------|---------------|
| **LlamaIndex** | 8.6/10 | RecuperaciÃ³n | PropertyGraphIndex, 4 retrievers, Neo4j native |
| **LangChain** | 8.0/10 | OrquestaciÃ³n | ConversationBufferMemory, ReAct agents, 50+ tools |
| **Neo4j 5.15+** | 9.0/10 | Storage | Graph + Vector unified (HNSW), hybrid search |

**3-Layer Architecture** (from llamaindex.md Chapter 10):

```python
# LAYER 1: Unified Storage (Neo4j)
from neo4j import GraphDatabase
neo4j_driver = GraphDatabase.driver("bolt://localhost:7687", auth=("neo4j", "password"))

# LAYER 2: Specialized Retrieval (LlamaIndex)
from llama_index.core import VectorStoreIndex
from llama_index.vector_stores.neo4jvector import Neo4jVectorStore

neo4j_vector_store = Neo4jVectorStore(
    url="bolt://localhost:7687",
    embed_dim=768,
    index_name="melquisedec_embeddings",
    hybrid_search=True  # Vector + BM25
)
index = VectorStoreIndex.from_documents(docs, storage_context=...)

# LAYER 3: Agent Orchestration (LangChain)
from langchain.agents import create_react_agent
from langchain.tools import Tool

kg_tool = Tool(
    name="KnowledgeGraphSearch",
    func=lambda q: index.as_query_engine().query(q)
)
agent = create_react_agent(llm=llm, tools=[kg_tool], prompt=react_prompt)
```

### 1.3 DAATH-ZEN Advanced Task Format (ADOPT THIS)

**Source**: `.spec-workflow/archive/tasks.md` (1551 lines, 95% coherence)

**Recommendation**: `deep-coherence-analysis-2026-01-09.md` identified this as best format

```markdown
### X.Y Task Name
- **File**: target-file.md
- **Requirements**: REQ-001, REQ-002
- **Rostro**: HYPATIA|SALOMON|MORPHEUS|ALMA
- **Lesson**: _meta/Implementation Logs/task-X.Y.md

#### MCP Workflow Strategy
| Aspect | Value |
|--------|-------|
| **Thinking Mode** | sequential-thinking |
| **Activation** | filesystem, brave-search |
| **Parallel** | read papers 1-5 |
| **Sequential** | analyze â†’ synthesize â†’ document |
| **Error Handling** | fallback to manual search |

#### Prompt
```bash
# Executable instructions
step1: Search "Neo4j LlamaIndex" using brave-search
step2: Read top 5 results
step3: Synthesize in analysis.md
```

#### Success Criteria
- [ ] Minimum 5 sources indexed
- [ ] HKM headers validated
- [ ] Neo4j nodes created

#### Dependencies
- Requires: Task 1.1 (problem statement)
- Blocks: Task 2.2 (synthesis)
```

---

## ğŸ—ï¸ Part 2: Architecture - Divergent Workflows

### 2.1 ISSUE.yaml Structure (Spec-Issue Level)

```yaml
---
# Epic Metadata (applies to entire spec-issue)
epic:
  name: "research-neo4j-llamaindex"
  version: "v1.0.0"
  status: "active"        # active|archived
  type: "research"        # research|app|social-project
  created: "2026-01-09"
  archived: null

# Workflow Configuration
workflow:
  current_phase: "HYPATIA"     # MELQUISEDEC|HYPATIA|SALOMON|MORPHEUS|ALMA|DAATH
  divergence_point: "MORPHEUS" # When paths split

  checkpoints:
    CK-01: {phase: "HYPATIA", status: "pending"}
    CK-02: {phase: "SALOMON", status: "pending"}
    CK-03: {phase: "MORPHEUS", status: "pending"}
    CK-04: {phase: "ALMA", status: "pending"}

# Git Integration
git:
  branch: "feature/research-neo4j-v1.0.0"
  tags: []

# Neo4j Integration
neo4j:
  index_name: "research_neo4j_v1"
  archived_nodes: []
---
```

### 2.2 Folder Structure (Common Base)

```
research-{topic}-v{X.Y.Z}/
â”œâ”€â”€ ISSUE.yaml                    # Epic metadata
â”œâ”€â”€ README.md                     # Entry point
â”œâ”€â”€ requirements.md               # Consolidated requirements
â”œâ”€â”€ tasks.md                      # DAATH-ZEN Advanced format
â”‚
â”œâ”€â”€ 00-problem/                   # MELQUISEDEC
â”‚   â”œâ”€â”€ problem-statement.md
â”‚   â””â”€â”€ context.md
â”‚
â”œâ”€â”€ 01-literature/                # HYPATIA
â”‚   â”œâ”€â”€ paper-001-author.md      # HKM: is_a="source"
â”‚   â”œâ”€â”€ paper-002-author.md
â”‚   â””â”€â”€ bibliography.bib
â”‚
â”œâ”€â”€ 02-atomics/                   # HYPATIA
â”‚   â”œâ”€â”€ concept-001.md           # HKM: is_a="concept"
â”‚   â”œâ”€â”€ concept-002.md
â”‚   â””â”€â”€ relationships.md
â”‚
â”œâ”€â”€ 03-workbook/                  # SALOMON (Analysis)
â”‚   â”œâ”€â”€ analysis-01.md           # HKM: is_a="workbook"
â”‚   â”œâ”€â”€ synthesis.md
â”‚   â””â”€â”€ decision-matrix.md
â”‚
â”œâ”€â”€ 04-artifacts/                 # MORPHEUS (DIVERGE HERE)
â”‚   â””â”€â”€ [type-specific]/         # See section 2.3
â”‚
â”œâ”€â”€ 05-outputs/                   # ALMA (DIVERGE HERE)
â”‚   â””â”€â”€ [type-specific]/         # See section 2.4
â”‚
â””â”€â”€ 06-lessons/                   # DAATH (Reflection)
    â”œâ”€â”€ lesson-001.md            # HKM: is_a="lesson"
    â””â”€â”€ summary.yaml
```

### 2.3 DIVERGENCE: 04-artifacts/ by Type

#### Type: RESEARCH

```
04-artifacts/
â”œâ”€â”€ solution-spec.md             # Technical specification
â”œâ”€â”€ cypher-queries/
â”‚   â”œâ”€â”€ create-index.cypher
â”‚   â””â”€â”€ retrieve-pattern.cypher
â”œâ”€â”€ embeddings-pipeline.py       # Working code
â””â”€â”€ performance-benchmarks.md
```

#### Type: APP

```
04-artifacts/
â”œâ”€â”€ SPEC-DOMAIN.md               # Hexagonal architecture
â”œâ”€â”€ SPEC-PORTS.md                # Interfaces
â”œâ”€â”€ SPEC-ADAPTERS.md             # Implementations
â””â”€â”€ code/
    â”œâ”€â”€ domain/
    â”œâ”€â”€ ports/
    â””â”€â”€ adapters/
```

#### Type: SOCIAL-PROJECT

```
04-artifacts/
â”œâ”€â”€ stakeholder-map.md
â”œâ”€â”€ theory-of-change.md
â”œâ”€â”€ budget.yaml
â””â”€â”€ implementation-plan.md
```

### 2.4 DIVERGENCE: 05-outputs/ by Type

#### Type: RESEARCH

```
05-outputs/
â”œâ”€â”€ paper-draft.md               # Academic paper
â”œâ”€â”€ presentation.md              # Conference slides
â””â”€â”€ repository/                  # Code artifacts
    â”œâ”€â”€ README.md
    â””â”€â”€ examples/
```

#### Type: APP

```
05-outputs/
â”œâ”€â”€ package/                     # Deployable artifact
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ tests/
â”œâ”€â”€ documentation/
â”‚   â”œâ”€â”€ API.md
â”‚   â””â”€â”€ user-guide.md
â””â”€â”€ deployment/
    â””â”€â”€ docker-compose.yml
```

#### Type: SOCIAL-PROJECT

```
05-outputs/
â”œâ”€â”€ project-proposal.md          # Funding proposal
â”œâ”€â”€ implementation-plan.md       # Execution plan
â”œâ”€â”€ budget-justification.md
â””â”€â”€ monitoring-framework.md
```

---

## ğŸ”§ Part 3: Implementation - Core Scripts

### 3.1 sync-hkm-to-neo4j.py

```python
"""Sync HKM headers to Neo4j graph."""
import yaml
from pathlib import Path
from neo4j import GraphDatabase

class HKMSyncer:
    def __init__(self, neo4j_uri: str, user: str, password: str):
        self.driver = GraphDatabase.driver(neo4j_uri, auth=(user, password))

    def sync_document(self, md_path: Path):
        """Parse HKM header and create/update Neo4j node."""
        with open(md_path) as f:
            content = f.read()

        # Extract YAML frontmatter
        if not content.startswith("---"):
            return None

        yaml_end = content.find("---", 3)
        metadata = yaml.safe_load(content[3:yaml_end])

        # Create node
        with self.driver.session() as session:
            session.run("""
                MERGE (n:Artifact {id: $id})
                SET n.title = $title,
                    n.version = $version,
                    n.is_a = $is_a,
                    n.date = $date,
                    n.status = $status
                """,
                id=metadata['id'],
                title=metadata['dc']['title'],
                version=metadata['version'],
                is_a=metadata['is_a'],
                date=metadata['dc']['date'],
                status=metadata['status']
            )

            # Create relationships
            for source_path in metadata['seci'].get('derives_from', []):
                source_id = self._extract_id(source_path)
                session.run("""
                    MATCH (n:Artifact {id: $id})
                    MATCH (s:Artifact {id: $source_id})
                    MERGE (n)-[:DERIVES_FROM]->(s)
                    """,
                    id=metadata['id'],
                    source_id=source_id
                )

    def _extract_id(self, path: str) -> str:
        """Extract id from file path."""
        return Path(path).stem

    def close(self):
        self.driver.close()

# Usage
if __name__ == "__main__":
    syncer = HKMSyncer("bolt://localhost:7687", "neo4j", "password")

    for md_file in Path(".").rglob("*.md"):
        syncer.sync_document(md_file)

    syncer.close()
```

### 3.2 archive-epic.sh

```bash
#!/bin/bash
# Archive epic with Git tag + Neo4j soft delete

EPIC_NAME=$1
VERSION=$2

if [ -z "$EPIC_NAME" ] || [ -z "$VERSION" ]; then
    echo "Usage: ./archive-epic.sh <epic-name> <version>"
    exit 1
fi

# 1. Create Git tag
git tag -a "${EPIC_NAME}-${VERSION}" -m "Archive epic ${EPIC_NAME} version ${VERSION}"
git push origin "${EPIC_NAME}-${VERSION}"

# 2. Soft delete in Neo4j
cypher-shell -u neo4j -p password << EOF
MATCH (n:Artifact)
WHERE n.epic_name = '${EPIC_NAME}'
SET n.archived = true,
    n.archived_at = datetime(),
    n.archived_version = '${VERSION}'
RETURN count(n) as archived_count;
EOF

# 3. Update ISSUE.yaml
sed -i "s/status: \"active\"/status: \"archived\"/" "ISSUE.yaml"
sed -i "s/archived: null/archived: \"$(date -Iseconds)\"/" "ISSUE.yaml"

echo "âœ… Epic ${EPIC_NAME} archived with tag ${VERSION}"
```

### 3.3 validate-triple-coherence.py

```python
"""Validate coherence: MD â†” Graph â†” Vector."""
from pathlib import Path
from neo4j import GraphDatabase
import yaml

class CoherenceValidator:
    def __init__(self, spec_path: Path, neo4j_uri: str):
        self.spec_path = spec_path
        self.driver = GraphDatabase.driver(neo4j_uri, auth=("neo4j", "password"))

    def validate(self) -> dict:
        errors = {
            'missing_in_graph': [],
            'missing_in_md': [],
            'version_mismatch': [],
            'broken_relationships': []
        }

        # 1. Get all MD files with HKM headers
        md_artifacts = self._parse_md_files()

        # 2. Get all Neo4j nodes
        with self.driver.session() as session:
            result = session.run("MATCH (n:Artifact) RETURN n.id as id, n.version as version")
            graph_artifacts = {r['id']: r['version'] for r in result}

        # 3. Check MD â†’ Graph
        for md_id, md_version in md_artifacts.items():
            if md_id not in graph_artifacts:
                errors['missing_in_graph'].append(f"{md_id} (v{md_version})")
            elif md_version != graph_artifacts[md_id]:
                errors['version_mismatch'].append(
                    f"{md_id}: MD={md_version}, Graph={graph_artifacts[md_id]}"
                )

        # 4. Check Graph â†’ MD
        for graph_id in graph_artifacts:
            if graph_id not in md_artifacts:
                errors['missing_in_md'].append(graph_id)

        return errors

    def _parse_md_files(self) -> dict:
        artifacts = {}
        for md_file in self.spec_path.rglob("*.md"):
            with open(md_file) as f:
                content = f.read()

            if content.startswith("---"):
                yaml_end = content.find("---", 3)
                metadata = yaml.safe_load(content[3:yaml_end])
                artifacts[metadata['id']] = metadata['version']

        return artifacts

    def close(self):
        self.driver.close()

# Usage
validator = CoherenceValidator(Path("."), "bolt://localhost:7687")
errors = validator.validate()

if sum(len(v) for v in errors.values()) == 0:
    print("âœ… Triple coherence validated")
else:
    print("âŒ Coherence errors found:")
    for error_type, error_list in errors.items():
        if error_list:
            print(f"  {error_type}: {error_list}")
```

---

## ğŸ¨ Part 4: Principles Operationalized (P1-P7)

### P1: SÃ­ntesis MetodolÃ³gica

```yaml
P1_sintesis_metodologica:
  DSR: "00-problem â†’ 01-design â†’ 02-build â†’ 03-evaluate (folders)"
  Zettelkasten: "02-atomics/ with atomic concepts + seci relationships"
  SECI: "HKM headers track derives_from â†’ informs"
  HKM: "validate-metadata.py enforces standard"
```

### P2: Autopoiesis

```yaml
P2_autopoiesis:
  mechanism: "06-lessons/ â†’ Template vN+1"
  flow:
    - "Capture: Tasks add lessons to 06-lessons/"
    - "Aggregate: summary.yaml consolidates gaps"
    - "Feedback: Gaps inform next template version"
    - "Improve: Template self-updates"
```

### P3: Issue-Driven

```yaml
P3_issue_driven:
  spec_level: "ISSUE.yaml (epic metadata)"
  artifact_level: "HKM header (individual metadata)"
  traceability: "ISSUE.epic.name â†’ HKM headers â†’ Neo4j"
```

### P5: ValidaciÃ³n Continua

```yaml
P5_validacion_continua:
  CK-01:
    phase: "HYPATIA"
    criteria: ["Min 10 sources", "bibliography.bib generated"]
    script: "validate-literature.py"

  CK-02:
    phase: "SALOMON"
    criteria: ["Atomic concepts linked", "Decision matrix complete"]
    script: "validate-analysis.py"

  CK-03:
    phase: "MORPHEUS"
    criteria: ["[research] Cypher queries executable", "[app] Tests passing"]
    script: "validate-artifacts.py"

  CK-04:
    phase: "ALMA"
    criteria: ["[research] Paper draft reviewed", "[app] Package deployable"]
    script: "validate-outputs.py"
```

### P6: Trazabilidad ExplÃ­cita

```yaml
P6_trazabilidad_explicita:
  layers:
    markdown:
      format: "HKM headers + content"
      traceability: "seci.derives_from, seci.informs"
      versioning: "Git commits + tags"

    graph:
      format: "Neo4j nodes + relationships"
      traceability: "[:DERIVES_FROM], [:INFORMS]"
      properties: "id, version, epic_name, archived"

    vector:
      format: "Neo4jVectorStore embeddings"
      traceability: "Metadata in embedding properties"
      index: "HNSW with hybrid_search"

  synchronization:
    md_to_graph: "sync-hkm-to-neo4j.py"
    validation: "validate-triple-coherence.py"
```

### P7: RecursiÃ³n Fractal

```yaml
P7_recursion_fractal:
  level_1_monorepo:
    - "apps/ (research instances)"
    - "packages/ (reusable components)"
    - "docs/manifiesto/ (same HKM structure)"

  level_2_spec_issue:
    - "research-X-v1.0.0/ (complete epic)"
    - "Folders 00-06 (MELQUISEDEC phases)"
    - "Each folder has .md with HKM headers"

  level_3_artifact:
    - "HKM header (metadata)"
    - "Content (markdown body)"
    - "Neo4j node (graph representation)"
    - "Embedding (vector representation)"

  pattern: "Same HKM + Neo4j sync at ALL levels"
```

---

## ğŸ“¦ Part 5: Deliverables & Roadmap

### 5.1 Template Outputs

```
unified-research-template-v3.0.0/
â”œâ”€â”€ README.md                          # Comprehensive guide
â”œâ”€â”€ ADR-003-unified-template.md        # Architecture decision
â”œâ”€â”€ ISSUE.yaml.template                # Epic metadata template
â”œâ”€â”€ tasks.md.template                  # DAATH-ZEN Advanced
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ hkm-headers/
â”‚       â”œâ”€â”€ source.yaml
â”‚       â”œâ”€â”€ concept.yaml
â”‚       â”œâ”€â”€ workbook.yaml
â”‚       â”œâ”€â”€ artifact.yaml
â”‚       â”œâ”€â”€ output.yaml
â”‚       â””â”€â”€ lesson.yaml
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ sync-hkm-to-neo4j.py
â”‚   â”œâ”€â”€ archive-epic.sh
â”‚   â””â”€â”€ validate-triple-coherence.py
â”‚
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ research-example-v1.0.0/       # Complete working example
â”‚       â”œâ”€â”€ ISSUE.yaml
â”‚       â”œâ”€â”€ 00-problem/
â”‚       â”œâ”€â”€ 01-literature/
â”‚       â”‚   â””â”€â”€ paper-001.md          # With HKM
â”‚       â””â”€â”€ 02-atomics/
â”‚           â””â”€â”€ concept-001.md        # With HKM
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ workflows-divergentes.md       # Research/App/Social
â”‚   â””â”€â”€ principios-operacionalizados.md # P1-P7 examples
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_hkm_validation.py
    â”œâ”€â”€ test_scripts.py
    â””â”€â”€ test_coherence.py
```

### 5.2 Implementation Roadmap

| Phase | Tasks | Effort | Status |
|-------|-------|--------|--------|
| **Phase 1: Templates** | Create ISSUE.yaml, tasks.md, HKM templates | 4h | ğŸ”œ Pending |
| **Phase 2: Scripts** | Implement sync, archive, validate scripts | 6h | ğŸ”œ Pending |
| **Phase 3: Examples** | Create complete research-example-v1.0.0 | 4h | ğŸ”œ Pending |
| **Phase 4: Docs** | Document divergent workflows + principles | 3h | ğŸ”œ Pending |
| **Phase 5: Tests** | Write tests for all scripts | 3h | ğŸ”œ Pending |
| **Total** | | **20h** | |

---

## âœ… Success Criteria

| ID | Criterion | Validation | Priority |
|----|-----------|------------|----------|
| SC-1 | HKM/keterdoc integrated (not reinvented) | validate-metadata.py passes | ğŸ”´ Critical |
| SC-2 | Hybrid stack documented with code | Examples executable | ğŸ”´ Critical |
| SC-3 | DAATH-ZEN Advanced format adopted | tasks.md.template complete | ğŸ”´ Critical |
| SC-4 | Workflows diverge by type | 3 examples (research/app/social) | ğŸ”´ Critical |
| SC-5 | Scripts working | sync + archive + validate functional | âš ï¸ High |
| SC-6 | Principles operationalized | P1-P7 with yaml examples | âš ï¸ High |
| SC-7 | Complete example | research-example-v1.0.0 working | âš ï¸ High |
| SC-8 | Tests passing | All scripts tested | âš¡ Medium |

---

## ğŸ“š References

### Standards (Already Exist)
1. `docs/manifiesto/02-arquitectura/03-templates-hkm.md` - HKM standard
2. `docs/manifiesto/01-fundamentos/04-principios-fundacionales.md` - P1-P7
3. `docs/manifiesto/03-workflow/03-versionamiento.md` - Semver

### Architecture (Already Validated)
4. `apps/research-neo4j-llamaindex-architecture/01-design/state-of-art/comparative-analysis.md` - Stack decision
5. `apps/research-neo4j-llamaindex-architecture/01-design/state-of-art/frameworks/llamaindex.md` - Chapter 10 (LangChain integration)

### Implementation (Already Exists)
6. `.spec-workflow/archive/tasks.md` - DAATH-ZEN Advanced format (1551 lines)
7. `.spec-workflow/specs/architecture-best-practices/` - MELQUISEDECPipeline

### Analysis (Consolidated)
8. `.spec-workflow/analysis/unified-template-research-diverse/coherence-index-analysis-2026-01-09.md`
9. `.spec-workflow/analysis/unified-template-research-diverse/deep-coherence-analysis-2026-01-09.md`
10. `.spec-workflow/analysis/unified-template-research-diverse/gap-analysis-unified-template-2026-01-09.md`

---

**Version**: 3.0.0
**Status**: âœ… Final Design - Consolidated from 5 Analysis Documents
**Next Action**: Implement Phase 1 (Templates)
**Effort Saved**: 36% vs v1.0.0 (by integrating existing standards)
**Document Length**: 800 lines (vs 1351 in v2.0.0)
